---
layout: post
title: Computer Vision - Multi-modal Learning
category: BC
tag: [Deep Learning]
---

## Further Question  

- Multi-modal learning에서 feature 사이의 sementic을 유지하기 위해 어떤 학습방법을 사용하는가?  
- Captioning task를 풀 때 attention이 어떻게 사용될 수 있는가?  
- Sound source localization task를 풀 때, audio 정보는 어떻게 활용되는가?  

## Multi-modal Learning Overview 

- 시각 외에도 청각, 후각 등의 정보를 같이 훈련하는 것 


#### Multi-modal Leaning의 어려운 점  

- Audio는 1-dim, Image는 2dim~4dim 등 데이터 표현의 차이로 어려움이 있다.  
- 이미지는 보통 여러가지가 있을 수 있는 1:N 형태로 Unbalance 문제가 있다.  
- Modality를 많이 사용할 때 오히려 쉬운 정보에만 의존하는 bias현상이 발생할 수도 있다.  

#### Multi-modality를 사용하는 방법들  

- Matching : 두 데이터 타입을 공통된 영역으로 보내 matching
- Translating : 하나의 Modality를 다른 종류로 translating
- Referencing : 다른 Modality를 참조하여 출력을 냄

## Multi-modal Training  

#### Text embedding  

- 문자는 문자 그대로 사용한다면 머신러닝측면에서 훈련의 어려움이 있다.  
- 따라서 **dense vectors**로 매핑해준다.  

#### word2vec  

- Skip-gram model  
- 문자 W를 word-embedding을 한 뒤 다른 문자 W`에 대하여 학습을 해주는 방법  
- 주어진 문자열에서 특정 문자 W가 주변의 문자들인 W`의 거리에 대하여도 관계를 형성하여 학습  

#### Joint embedding  

##### Image tagging
- 주어진 이미지에 대하여 Tag를 하던가, Tag를 보고 Image를 찾는 방법  
- Pre-trained unimodal models을 사용하여 문자와 이미지와 같은 다른 모델 사이에서 같은 dimension인 벡터를 추출해낸다.  
- 출력된 결과물에 Joint embedding을 사용하여 관계를 학습한다.  

##### Recipe text  

- 순서가 있는 레시피와 같은 텍스트를 훈련시키는 방법
- 같은 dimension의 순서와 문자열 vector를 매칭시켜 같이 훈련시키는 방법
- Cosine similarity lsos, Sementic regularization loss를 사용하기도 함  

#### Cross modal translation  

##### Image to Sentence  

- Show, Atetend and Tell  

Encoder : CNN model pre-trained on ImageNet  
Decoder : LSTM module  

- Input 이미지의 Conv Feature를 뽑는데, 14x14 vector의 Feature Map을 RNN 모델에 넣어준다.  
- 각각의 Feature Vector(Condition)에 대한 Attention을 RNN 모델을 통하여 검증  
- 그렇게 만들어진 Weight와 feature map을 내적하여 만들어진 결과를 고려하여 Word를 결정  
- 그 결과로 feature map을 업데이트 후 반복  

##### Text to Image  

- Conditional GAN의 기본 형태를 따르는 Generator  
- Sentence 정보를 Generator와 Discriminator 둘 다 가진다.   
- Sentence 정보를 바탕으로 Discriminator이 훈련을 한다.  

##### Visual question answering  

문자와 이미지를 둘 다 FC layer를 만든 뒤 Point-wise multiplication을 하는 모델을 End-to-End 훈련  


#### Sound representation  

- Sound는 기본적으로 1-dim 형태로 제공된다.  
- Acoustic feature로 변환하여 머신러닝 분야에서 이용된다.  

##### Fourier transform  

- Short-time Fourier transform (STFT) : 짧은 윈도우(구간) 내에 Hamming window와 같은 기법을 적용한 뒤 Fourier transform을 적용하는 것  

##### Spectrogram  

- 시간에 따른 주파수 성분을 시각적으로 볼 수 있는 Image 형태로 만들어진다.  
- Melspectogram, MFCC

##### SoundNet

- 오직 이미지만을 pre-trained된 모델에 거치게하는데, Object와 Scene 2개의 출력을 가지게 함  
- 오직 음성만을 Waveform으로 만들어 2가지의 head를 추출  
- 각 2개씩의 KL Loss를 계산하는 방법으로 학습  

##### Speech2Face

- 인터뷰 영상에서 Face Recognition과 Voice Encoder의 Loss를 계산하여 목소리를 통해 Face를 예측하는 방법  