---
layout: post
title: Go Go - 5
category: Go
tag: [Go]
---

오늘은 net/html 모듈을 가지고 놀아봤다.  
`golang.org/x/net/html`은 비공식 패키지로 Go 팀이 관리하는 모듈이다.  

#### net/html  

비공식 패키지이므로 따로 다운로드가 필요하다.  
터미널에서 해당 명령어를 입력한다.  
```
go get golang.org/x/net/html
```


html 패키지에는 다음이 정의되어있다.  

```go
package golang.org/x/net/html

type Node struct{
    Parent, FirstChild, LastChild, PrevSibling, NextSibling *Node

	Type      NodeType
	DataAtom  atom.Atom
	Data      string
	Namespace string
	Attr      []Attribute
}

type NodeType int32

const (
    ErrorNode NodeType = iota //0부터 차례대로 번호를 매김
    TextNode
    DocumentNode
    ElementNode
    CommentNode
    DoctypeNode
)

type Attribute struct{
    Key, Val string
}

func Parse(r io.Reader) (*Node, error)

```

보면 Node 구조체는 트리 구조로 구성되어 있다.  

`Parse(r io.Reader)`를 보면 io.Reader 형태의 인터페이스를 매개변수로 받고, Node 포인터와 error를 반환한다.  

이 정보를 가지고 구현을 해보자.  

#### 해당 웹페이지에서 링크를 재귀적으로 검색  

```go
import (
	"fmt"
	"io"
	"net/http"
	"os"

	"golang.org/x/net/html"
)

// 146쪽 재귀 호출로 링크를 찾음

func main() {

	url := os.Args[1]

	resp, err := http.Get(url)

	if err != nil {
		fmt.Fprintf(os.Stderr, "fetch: %v\n", err)
		return
	}

	findLink(resp.Body)
	resp.Body.Close()
}
```

main()에서는 url를 명령행 인자로 받은 뒤 요청을 보낸다.  
그 다음 Reader와 Closer 인터페이스를 가진 `response.Body` 를 findLink()에 매개변수로 넣는다.  

```go
func findLink(r io.Reader) {
	doc, err := html.Parse(r)
	if err != nil {
		fmt.Fprintf(os.Stderr, "findlinks1: %v\n", err)
		os.Exit(1)
	}
	for _, link := range visit(nil, doc) {
		fmt.Println(link)
	}
}
```

html의 parse 함수를 사용한다. `Node*`를 반환한다.   
다음 얻어진 doc으로 visit함수를 돌린다.  
index는 필요 없기에 for 문의 첫번째를 _로 두었다.  

```go
func visit(links []string, n *html.Node) []string {
	if n.Type == html.ElementNode && n.Data == "a" {
		for _, a := range n.Attr {
			if a.Key == "href" {
				links = append(links, a.Val)
			}
		}
	}

	for c := n.FirstChild; c != nil; c = c.NextSibling {
		links = visit(links, c)
	}
	return links
}
```  

visit함수는 links들과 Node를 받는다.  

이 때 노드의 타입이 Element 타입이고, `<a` 로 시작하는 Element를 찾는다.  
다음 a의 키가 href, 즉 두개의 조건문을 합치면 `<a href` 를 찾는, 하이퍼링크들을 찾는 코드이다.  
해당 조건을 찾으면, 데이터를 `links` 배열에 넣는다.  

다음 재귀함수를 돌리는데, 첫번째 자식부터 옆에 형제까지 재귀함수를 돌린다.  
즉 트리구조에서 루트를 기준으로 재귀함수를 돌리면 리프노드까지 쭉 재귀함수가 돈다.  

이렇게 모든 링크들을 links에 넣은 다음, return 한다.  
다음 이렇게 추출된 링크들을 단순히 print함으로써 해당 코드를 끝냈다. 